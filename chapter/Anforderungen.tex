\section{Anforderungen}
Im Folgenden sollen alle von der Abteilung formulierten Erwartungen, die im Rahmen dieser Praxisarbeit erreicht werden sollen, erläutert werden. Diese Anforderungen teilen sich in die vier Grundaufgaben auf, die in Grundlagen beschrieben wurden.
\subsection{Datenbereitstellung}
Zuerst müssen die Daten, auf die mithilfe der API zugegriffen wird, erstellt werden und abrufbar gemacht werden.
\subsubsection{Erstellung der Datengrundlage}
Die Basis der Test-API bildet die DynamoDB-Tabelle „user-db“ (in Zukunft ``Tabelle''), mit der E-Mail-Adresse des Nutzers als Schlüsselelement. Zwar ist dies nicht von DynamoDB vorgeschrieben, jedoch sind in dieser Implementation die Spalten ebenfalls (auf semantischer Ebene) festgelegt, um die Komplexität der Datenverarbeitung kontrollieren zu können.  Dazu sind die Informationen, die zu einem Nutzer abgespeichert werden in diesem Kontext konstant, weshalb flexible Spalten keinen Vorteil bieten. \newpage 
Die Spalten sind folgendermaßen aufgeteilt.

\begin{table}[hbt]
\centering
\begin{minipage}[t]{.5\textwidth} % Breite, z.B. 1\textwidth		
\caption{Aufbau der Tabelle} % Überschrift
\begin{tabularx}{\columnwidth}{rr}
\toprule
Spalte & Beschreibung\\
\midrule
E-Mail & E-Mail-Adresse des Nutzers\\
Name   & Name des Nutzers\\
Status & Aktivitäts-Status (Aktiv/Inaktiv)\\
\bottomrule
\end{tabularx}
\source{Eigene Darstellung} % Quelle
\label{tab:schema}
\end{minipage}
\end{table}
\subsubsection{Die Test-API}
Unter Nutzung dieser Daten soll die Test-API folgende Methoden anbieten. Eine Varianz soll in den Methoden gegeben sein, damit unterschiedliche Laufzeitverhalten und auftretende Fehler simuliert und gemessen werden können.
\paragraph{Abfrage ``GetUser''}
Als Parameter für diese Abfrage erwartet die API einen String, welcher die E-Mail-Adresse beinhalten soll, zu der die Nutzerdaten angefordert werden. Zudem wird nach dem GraphQL-Standard erwartet, dass alle Spalten angegeben werden, deren Ausgabe vom Nutzer erwünscht sind.
\paragraph{Abfrage ``GetUsers''}
Hier erwartet die API nur die auszugebenen Spalten als Parameter. Ausgegeben werden dann die angeforderten Spalten aller Nutzer, die in der Tabelle hinterlegt sind.
\paragraph{Abfrage ``AddUser''}
Die API erwartet hier für jede Spalte der Tabelle jeweils einen String. Dazu erwartet die API eine Angabe zu den Spalten, die nach der Erstellung des Nutzers ausgegeben werden sollen.  Mit diesen Informationen wird dann ein Eintrag in der Tabelle erstellt, und die gewünschten Spalten des erstellten Nutzers ausgegeben.\newline
Diese API funktioniert aber nur, wenn das Backend implementiert ist. Dafür ist Terraform zuständig.
\subsubsection{Terraform}
Das Terraform-Backend soll alle Hintergrundprozesse handhaben, sodass die API ohne manuelle Bearbeitung funktionieren kann. Zu diesen Prozessen gehören die Datenbank-Definition, das Berechtigungs-Management, die Resolver für die jeweiligen Methoden, und die Aktivierung des Loggings. Ist all das implementiert, kann ein Nutzer im Testsystem auf Daten zugreifen, die dabei entstehenden Informationen können jedoch noch nicht vollständig verarbeitet werden, da die Daten noch nicht überallhin verteilt werden können:
\subsection{Datentransport}
Die Infrastruktur für die AWS-Interne Weiterleitung von Daten besteht schon. Um Daten der API in ein Datadog-Dashboard zu integrieren, muss jedoch die Infrastruktur selbst aufgebaut werden.
\subsubsection{Theorie der Integration}
Zuerst muss die Verbindung zwischen dem AWS-Account, in dessen Namen auch die API und Tabelle erstellt wurden, und Datadog geknüpft werden. Dafür bietet Datadog eine Oberfläche. Um die Verbindung herzustellen, werden zwei Tokens generiert: ein ``API-Key'' und ein ``Application-Key''. Mit diesen beiden Tokens kann dann in einer bestimmten Region die Schnittstelle seitens Datadog geöffnet werden. Die Schnittstelle seitens AWS ist über das Tool „CloudFormation“ möglich. Dort muss ein Stack erstellt werden, welcher ebenfalls mit dem generierten Application-Key versehen wird, wodurch dann die beiden Schnittstellen miteinander verbunden sind. Ein Datenfluss existiert jedoch trotzdem nicht, da es in der Testumgebung keine Endnutzer gibt; dieser muss manuell in einer Programmiersprache über eine Lambda-Funktion implementiert werden. In diesem Fall wird die Sprache Python verwendet. 

\subsection{Datenabruf}
\subsubsection{Lambda-Funktion}
Für Testzwecke werden im Rahmen dieser Praxisarbeit zwei Lambda-Funktionen erstellt. In der einen Funktion wird eine korrekte, in der anderen eine inkorrekte Abfrage simuliert. Dabei werden Daten zu der Ausgabe und der Antwort-Zeit weitergegeben.  Diese können dann in DataDog als Dashboard umgesetzt werden. 

\subsection{Daten-Monitoring}
Im Rahmen des Daten-Monitorings sollen zwei verschiedene Erkenntnisse gesammelt werden: Zum einen soll ermittelt werden, ob die API eine stabile Response time hat, und zum anderen sollen Fehlerquellen ermittelt und ausgewertet werden. Ersteres soll in DataDog umgesetzt werden.
\subsection{DataDog}
Um Effizienz und Effektivität kontrollieren zu können, sind die Minimalanforderungen ein Graph für die Response-Time und ein Graph über die Fehlerhäufigkeit. Im Rahmen dieser Praxisarbeit werden jeweils eine KPI für Effizienz und Effektivität abgedeckt, während weitere bei Bedarf in der Zukunft hinzugefügt werden können. dabei wird als Hauptkriterium die Rückmeldung der Endnutzer von Relevanz sein. 

\subsubsection{Effizienz}
Anhand einer Timeline soll das Dashboard dem Endnutzer ermöglichen, die KPI ``Response time'' zu überprüfen. \cite{DatadogAWS2024}. Das soll anhand eines Zeitgraphen erreicht werden, auf dem die Antwortzeit der Anfragen gemessen werden. Damit Trends leichter erkennbar sind, soll ebenfalls eine Trendlinie über den Graphen gelegt werden. 

\subsubsection{Effektivität}
Das Dashboard soll dem Endnutzer ermöglichen, das Verhältnis zwischen erfolgreichen und fehlerhaften Anfragen einzusehen, damit zu jedem Zeitpunkt ein Eindruck über die Funktionalität der API möglich ist.
\newline
Die Auswertung von Fehlern soll über CloudWatch ablaufen.
\subsection{CloudWatch}
Nachdem die API in AWS integriert wurde, löst CloudWatch bei Fehlern selbstständig Alarme aus, weshalb keine weitere Infrastruktur aufgebaut werden muss. Die Logs werden danach sofort gesammelt, und lösen entsprechende Alarme aus.

